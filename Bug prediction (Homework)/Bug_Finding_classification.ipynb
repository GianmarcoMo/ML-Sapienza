{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bug Finding classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOF0mRo13xVt"
      },
      "source": [
        "# **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCsvS2TE3wqB",
        "outputId": "722720d4-ed41-40c7-bd91-3efd8ae4716a"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.naive_bayes import *\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "print('Libraries imported.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmxNbTDRweI6"
      },
      "source": [
        "# **Read the CSV from Google drive**\n",
        "\n",
        "Store the dataset on a Google drive's folder to avoid to upload it every time open colab.\n",
        "\n",
        "1. Mount the Google drive giving permission; \n",
        "2. Insert the files' path and read the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcZIX_6jrUB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba0ea74-3764-4e65-861a-30b1352735b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1YL-ME3yunP",
        "outputId": "8b8e7006-5c8d-42f8-ce1f-05ef52acd803"
      },
      "source": [
        "# Dataset path\n",
        "path = \"/content/drive/MyDrive/data/midterm_1/\"\n",
        "blind_dt = pd.read_csv(path+'blind_test.csv', sep='\\t')\n",
        "print('File %s loaded: %d samples.' %( 'blind_test', len(blind_dt.instructions) ))\n",
        "\n",
        "# Dataset to train model\n",
        "mapping_dt = pd.read_csv(path+'mapping_traces_O0.csv', sep='\\t')\n",
        "print('File %s loaded: %d samples.' %( 'mapping_traces_O0', len(blind_dt.instructions) ))\n",
        "#print(mapping_dt)\n",
        "\n",
        "# show an example\n",
        "#id = random.randrange(0,blind_dt.shape[0])\n",
        "#print(\"\\nExample ID: %d \\n%s\" %(id, blind_dt.iloc[id]))\n",
        "\n",
        "#id = random.randrange(0, mapping_dt.shape[0])\n",
        "#print('\\nExampe ID: %d \\n%s' %(id, mapping_dt.iloc[id]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File blind_test loaded: 10000 samples.\n",
            "File mapping_traces_O0 loaded: 10000 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n4vwAxw99ox"
      },
      "source": [
        "**Join data about instructions and source_line**\n",
        "\n",
        "In this case, create the two dataset:\n",
        "- X and Y to use it in training process.\n",
        "\n",
        "X is a join of **instructions** and **source_line** and Y is a **set of output**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teB3L4Cy-V7a",
        "outputId": "4bea5778-4071-41cd-ade1-8c03ca909a5f"
      },
      "source": [
        "# Delete columns for mapping_trace_O0 file and create Y output\n",
        "mapping_dt_y = mapping_dt['bug']\n",
        "\n",
        "# Create a series for the join of 'instructions' and 'source_line'\n",
        "mapping_dt_x = (mapping_dt['instructions'] + mapping_dt['source_line'])\n",
        "\n",
        "print(\"Series created.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt4j0x-tABWw"
      },
      "source": [
        "# **Defining Vectorizer for text**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKWEucDKWnDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03a69d6a-83fb-40e4-b374-b6109e5c172c"
      },
      "source": [
        "vectorizer_type = \"tfid\" # \"count\" or \"tfid\"\n",
        "\n",
        "if vectorizer_type == \"count\":\n",
        "  vectorizer = CountVectorizer() # multinomial\n",
        "elif vectorizer_type == \"tfid\":\n",
        "  vectorizer = TfidfVectorizer()\n",
        "\n",
        "X_all = vectorizer.fit_transform(mapping_dt_x)\n",
        "\n",
        "# Show feature extracted\n",
        "#print(vectorizer.get_feature_names())\n",
        "y_all = mapping_dt_y\n",
        "\n",
        "print(X_all.shape)\n",
        "print(y_all.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 1235)\n",
            "(100000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuXTToZ3IEnu"
      },
      "source": [
        "# Split data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "764oNqP-IMe3",
        "outputId": "93eb9820-fef1-49bb-c21d-602d1b994ba2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
        "          test_size=0.20, random_state=16)\n",
        "\n",
        "print(\"Train: %d - Test: %d\" %(X_train.shape[0],X_test.shape[0]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 80000 - Test: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8onRoAq75Vw"
      },
      "source": [
        "# Create and fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEsMMc1074j8",
        "outputId": "6ca4bf8a-d9ce-4ff7-bbac-bdb7c8862649"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "start_time = datetime.now()\n",
        "model_type_1 = BernoulliNB().fit(X_train, y_train)\n",
        "print('Bernoulli Model created')\n",
        "end_time = datetime.now()\n",
        "print('Duration to fit the model: {}\\n'.format(end_time - start_time))\n",
        "\n",
        "start_time = datetime.now()\n",
        "model_type_2 = MultinomialNB().fit(X_train, y_train)\n",
        "print('Multinomial Model created')\n",
        "end_time = datetime.now()\n",
        "print('Duration to fit the model: {}\\n'.format(end_time - start_time))\n",
        "\n",
        "start_time = datetime.now()\n",
        "model_type_3 = svm.LinearSVC().fit(X_train, y_train)\n",
        "print('Support Vector Machine Model created')\n",
        "end_time = datetime.now()\n",
        "print('Duration to fit the model: {}\\n'.format(end_time - start_time))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Model created\n",
            "Duration to fit the model: 0:00:00.039199\n",
            "\n",
            "Multinomial Model created\n",
            "Duration to fit the model: 0:00:00.024033\n",
            "\n",
            "Support Vector Machine Model created\n",
            "Duration to fit the model: 0:00:01.212852\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmbqqHqF7_Xy"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBhIqljA8AbK",
        "outputId": "d8d1fcbd-df45-486e-aae2-f426d6adce82"
      },
      "source": [
        "start_time = datetime.now()\n",
        "\n",
        "print('Bernoulli model: ')\n",
        "y_pred_1 = model_type_1.predict(X_test)\n",
        "acc_1 = model_type_1.score(X_test, y_test)\n",
        "end_time = datetime.now()\n",
        "print('Duration to predict: {}'.format(end_time - start_time))\n",
        "\n",
        "print(classification_report(y_test, y_pred_1))\n",
        "print(\"Accuracy %.3f\" %acc_1)\n",
        "print('#####################################################\\n')\n",
        "# -------------------\n",
        "print('\\nMultinomial model: ')\n",
        "y_pred_2 = model_type_2.predict(X_test)\n",
        "acc_2 = model_type_2.score(X_test, y_test)    \n",
        "\n",
        "print(classification_report(y_test, y_pred_2))\n",
        "print(\"Accuracy %.3f\" %acc_2)\n",
        "\n",
        "print('#####################################################\\n')\n",
        "# -------------------\n",
        "print('Support Vector Machine model: ')\n",
        "y_pred_3 = model_type_3.predict(X_test)\n",
        "acc_3 = model_type_3.score(X_test, y_test)    \n",
        "print(\"Accuracy %.3f\" %acc_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli model: \n",
            "Duration to predict: 0:00:00.017670\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.87      0.75      9969\n",
            "           1       0.81      0.54      0.65     10031\n",
            "\n",
            "    accuracy                           0.71     20000\n",
            "   macro avg       0.73      0.71      0.70     20000\n",
            "weighted avg       0.73      0.71      0.70     20000\n",
            "\n",
            "Accuracy 0.706\n",
            "#####################################################\n",
            "\n",
            "\n",
            "Multinomial model: \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.72      0.61      9969\n",
            "           1       0.57      0.37      0.45     10031\n",
            "\n",
            "    accuracy                           0.54     20000\n",
            "   macro avg       0.55      0.55      0.53     20000\n",
            "weighted avg       0.55      0.54      0.53     20000\n",
            "\n",
            "Accuracy 0.544\n",
            "#####################################################\n",
            "\n",
            "Support Vector Machine model: \n",
            "Accuracy 0.797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib-rSz0Z9jMp"
      },
      "source": [
        "# **Prediction and writing txt file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o1PGXCt9hq0",
        "outputId": "4bdb8d45-5de2-436e-d49a-c56b0fd74780"
      },
      "source": [
        "# Delete useless columns\n",
        "blind_dt_x = blind_dt.drop(columns=['line_number', 'function_name', 'program'])\n",
        "\n",
        "with open('1805370.txt', 'w') as f:\n",
        "  start_time = datetime.now()\n",
        "  for i in range(blind_dt_x.shape[0]):\n",
        "    xnew1 = vectorizer.transform(blind_dt_x.iloc[i])\n",
        "    ynew1 = model_type_3.predict(xnew1)\n",
        "    f.write(str(ynew1[0]))\n",
        "    f.write('\\n')\n",
        "\n",
        "  end_time = datetime.now()\n",
        "  print('Duration to predict the value and write on file: {}'.format(end_time - start_time))\n",
        "  f.close\n",
        "  print('File .txt wrote.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duration to predict the value and write on file: 0:00:10.243975\n",
            "File .txt wrote.\n"
          ]
        }
      ]
    }
  ]
}